# -*- coding: utf-8 -*-
"""ERA_V3+Session8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kmFW9SNa_eMEdm35IjGRrmB-tIeMJ1St
"""

import torch
import copy
import random
import os
import shutil
import cv2
import numpy as np
import matplotlib.pyplot as plt
import torchvision
import torchvision.transforms as transforms
import albumentations as A
from albumentations.pytorch import ToTensorV2
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from tqdm import tqdm
from torchvision import datasets
import logging
import datetime
from torchsummary import summary

# Custom Dataset for CIFAR10
class cifar10dataset(torch.utils.data.Dataset):
    def __init__(self, dataset, transform=None):
        self.dataset = dataset  # CIFAR10 dataset
        self.transform = transform

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, idx):
        image, label = self.dataset[idx]  # Get image and label from CIFAR10 dataset

        # Apply transformation if provided
        if self.transform is not None:
            augmented = self.transform(image=np.array(image))  # Apply transform, ensuring image is a NumPy array
            image = augmented["image"]  # Extract augmented image
        else:
            # If no transform is applied, convert the image to a NumPy array
            image = np.array(image)
            # Transpose the image to the correct channel order (C, H, W)
            image = image.transpose((2, 0, 1))
            # Normalize the image
            image = A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))(image=image)['image']
            # Convert to PyTorch tensor
            image = ToTensorV2()(image=image)['image']


        return image, label

# Define the transform pipelines
train_transform = A.Compose(
    [
        A.SmallestMaxSize(max_size=160),
        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),
        A.RandomCrop(height=128, width=128),
        #A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.5),
        #A.RandomBrightnessContrast(p=0.5),
        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
        A.HorizontalFlip(p=0.5),
        A.CoarseDropout(max_holes=1, max_height=16, max_width=16, min_holes=1, min_height=16, min_width=16, fill_value=0, mask_fill_value=None, p=0.5),
        ToTensorV2(),
    ]
)

val_transform = A.Compose(
    [
        A.SmallestMaxSize(max_size=160),
        A.CenterCrop(height=128, width=128),
        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
        ToTensorV2(),
    ]
)

# Download CIFAR10 dataset
batch_size= 128

trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                        download=True, transform=None)
trainset = cifar10dataset(dataset=trainset, transform=train_transform)

trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                          shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                       download=True, transform=None)
testset = cifar10dataset(dataset=testset, transform=val_transform)

testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,
                                         shuffle=False, num_workers=2)

# Classes for CIFAR10
classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')

# Visualizing augmentations
def visualize_augmentations(dataset, idx=0, samples=10, cols=5):
    dataset = copy.deepcopy(dataset)

    # Temporarily remove complex transformations like Normalize and ToTensorV2 for visualization
    dataset.transform = A.Compose([t for t in dataset.transform if not isinstance(t, (A.Normalize, ToTensorV2))])

    rows = samples // cols
    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 6))

    for i in range(samples):
        image, _ = dataset[idx]  # Get image and label from dataset

        # Ensure the image is in NumPy format (required by Albumentations)
        if isinstance(image, torch.Tensor):
            image = image.permute(1, 2, 0).numpy()  # Convert tensor to numpy array (H, W, C)

        # Apply the augmentation pipeline (without normalization)
        augmented = dataset.transform(image=image)
        image = augmented["image"]  # Extract augmented image

        # Rescale image values if they are in the range [0, 255]
        if image.max() > 1:
            image = image / 255.0  # Rescale to [0, 1]

        # Clip image values to the range [0, 1] for proper visualization
        image = np.clip(image, 0, 1)

        # Display the augmented image
        ax.ravel()[i].imshow(image)
        ax.ravel()[i].set_axis_off()

    plt.tight_layout()
    plt.show()

# Visualizing a few samples
random.seed(42)
visualize_augmentations(trainset)

import matplotlib.pyplot as plt
import numpy as np

# functions to show an image


def imshow(img):
    img = img / 2 + 0.5     # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1, 2, 0)))
    plt.show()


# get some random training images
dataiter = iter(trainloader)
images, labels = next(dataiter)

# show images
imshow(torchvision.utils.make_grid(images))
# print labels
print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))

import torch.nn as nn
import torch.nn.functional as F


# Define the model
class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()


        self.Layer1 = nn.Sequential(
            nn.Conv2d(3, 16, 3, padding=1),       # (3, 32, 32) -> (16, 32, 32)
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(16),
            nn.Conv2d(16, 16, 3, groups= 16),                 # (16, 32, 32) -> (16, 32, 32)
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(16),
            nn.Conv2d(16, 32, 3, stride=2, padding=1),       # (16, 32, 32) -> (32, 16, 16 )
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(32),
            nn.Conv2d(32, 10, 1),
            nn.BatchNorm2d(10),                  # 1x1 Conv -> (10, 16, 16)
            nn.Dropout(0.15)
        )


        self.Layer2 = nn.Sequential(
            nn.Conv2d(10, 32, 3, padding=1),      # (10, 16, 16) -> (32, 16, 16)
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(32),
            nn.Conv2d(32, 64, 3, groups=32),                # (32, 16, 16) -> (64, 14, 14)
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(64),
            nn.Conv2d(64, 64, 3, dilation= 2, padding=2),     # (64, 14, 14) -> (64, 10, 10)
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(64),
            nn.Conv2d(64, 10, 1),
            nn.BatchNorm2d(10),                # 1x1 Conv -> (10, 10, 10)
            nn.Dropout(0.15)
        )


        self.Layer3 = nn.Sequential(
            nn.Conv2d(10, 64, 3, padding=1),               # (10, 10, 10) -> (64, 10, 10)
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(64),
            nn.Conv2d(64, 64, 3, groups=64, padding=1),               # (64, 10, 10) -> (64, 8, 8)
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(64),
            nn.Conv2d(64, 128, 3, dilation =2, padding=2),              # (64, 8, 8) -> (128, 4, 4)
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(128),
            nn.Conv2d(128, 10, 1),
            nn.BatchNorm2d(10),                # 1x1 Conv -> (10, 4, 4)
            nn.Dropout(0.15)
        )


        self.Layer4 = nn.Sequential(
            nn.Conv2d(10, 128, 2, padding=1),               # (10, 4, 4) -> (128, 4, 4)
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(128),
            nn.Conv2d(128, 128, 2, groups= 128, padding=1), # (128, 4. 4) -> (128, 3, 3)
            nn.ReLU(inplace=True),
            nn.BatchNorm2d(128),
        )


        self.GAP = nn.Sequential(
            nn.AdaptiveAvgPool2d(1)                        # (128, 1, 1)
        )


        # Fully connected layer (flatten the feature map)
        self.fc = nn.Sequential(
            nn.Linear(128, 256),
            nn.ReLU(inplace=True),
            nn.Linear(256, 10) # Flatten and output 10 classes
        )

    def forward(self, x):
        x = self.Layer1(x)
        x = self.Layer2(x)
        x = self.Layer3(x)
        x = self.Layer4(x)
        x = self.GAP(x)
        x = x.view(x.size(0), -1)  # Flatten the output of Layer5 (16 channels, 3x3 spatial size)
        x = self.fc(x)
        return F.log_softmax(x, dim=1)

net = Net()

use_cuda = torch.cuda.is_available()
device = torch.device("cuda" if use_cuda else "cpu")

model = Net().to(device)
summary(model, input_size=(3, 32, 32))

import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)

best_test_acc = 0.0
best_model_state = None


def train(model, device, train_loader, optimizer, epoch):
    model.train()
    pbar = tqdm(train_loader)
    correct = 0
    total = 0
    for batch_idx, (data, target) in enumerate(pbar):
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = F.nll_loss(output, target)
        loss.backward()
        optimizer.step()
        _, predicted = torch.max(output, 1)
        total += target.size(0)
        correct += (predicted == target).sum().item()
        accuracy = 100. * correct / total
        pbar.set_description(f"Epoch {epoch} - Loss: {loss.item():.4f} - Acc: {accuracy:.2f}%")
    print(f"Training Accuracy: {accuracy:.2f}%")


def test(model, device, test_loader):
    global best_test_acc, best_model_state
    model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += F.nll_loss(output, target, reduction='sum').item()
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()
    #test_loss /= len(test_loader.dataset)
    accuracy = 100. * correct / len(test_loader.dataset)
    #print(f"Validation Accuracy: {accuracy:.2f}%")

    print('\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\n'.format(
        test_loss, correct, len(test_loader.dataset),
        accuracy))

    if accuracy > best_test_acc:
        best_test_acc = accuracy
        best_model_state = model.state_dict()
        print(f"New best model found with accuracy: {best_test_acc:.2f}%")

    return accuracy

# Model Training and Saving
model = Net().to(device)
optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)
criterion = nn.CrossEntropyLoss()

for epoch in range(0, 80):  # Train for 50 epochs
    train(model, device, trainloader, optimizer, epoch)
    test(model, device, testloader)

# Save the best model
if best_model_state is not None:
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    save_path = f'CIFAR_best_model_{timestamp}.pth'
    torch.save({
        'model_state_dict': best_model_state,
        'Test_accuracy': best_test_acc,
        'epoch': epoch  # Save the current epoch
    }, save_path)
    print(f"Best model saved to {save_path}")

import datetime

# Load the best saved model
checkpoint = torch.load('CIFAR_best_model_20241226_102655.pth')
model = Net().to(device)
model.load_state_dict(checkpoint['model_state_dict'])
optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # Fine-tuning with a smaller LR
best_test_acc = checkpoint['Test_accuracy']
start_epoch = checkpoint['epoch'] + 1

# Introduce a learning rate scheduler
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=5, verbose=True)

# Retrain for 20 more epochs
for epoch in range(start_epoch, start_epoch + 30):
    train(model, device, trainloader, optimizer, epoch)
    validation_accuracy = test(model, device, testloader)
    scheduler.step(validation_accuracy)

# Save the retrained model if it's the best
if best_model_state is not None:
    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    retrain_save_path = f'CIFAR_retrained_model_{timestamp}.pth'
    torch.save({
        'model_state_dict': best_model_state,
        'Test_accuracy': best_test_acc,
        'epoch': epoch
    }, retrain_save_path)
    print(f"Retrained model saved to {retrain_save_path}")

dataiter = iter(testloader)
images, labels = next(dataiter)

# print images
imshow(torchvision.utils.make_grid(images))
print('GroundTruth: ', ' '.join(f'{classes[labels[j]]:5s}' for j in range(4)))

